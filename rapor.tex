    \documentclass[conference]{IEEEtran}
    \usepackage[utf8]{inputenc}
    \usepackage[T1]{fontenc}
    \usepackage[turkish]{babel}
    \usepackage{etoolbox}
    \AtBeginDocument{\shorthandoff{=}}
    \usepackage{graphicx}
    \usepackage{amsmath}
\usepackage{amssymb}  % \checkmark için
    \usepackage{booktabs} % Güzel tablolar için
    \usepackage{float}    % [H] ile figürleri sabitlemek için
    \usepackage{subcaption} % Alt figürler için (subfigure)
    \usepackage[hyphens]{url} % URL'leri düzgün kırmak için
    \usepackage{hyperref} % Referanslar için
    \usepackage{multirow} % Çok satırlı tablolar için
    \usepackage{array}    % Tablo genişliği için

    % Doküman Başlığı ve Yazar Bilgisi
    \title{Öğrenme Modellerinde Özellik Seçimi: Online News Popularity Veri Kümesi Üzerinde Karşılaştırmalı Analiz}

    % Kullanıcının istediği yazar bilgisi
    \author{\IEEEauthorblockN{Muhammed Kayra Bulut - 25501805}
    \IEEEauthorblockA{Makine Öğrenmesi Dersi 2. Ödevi}
    }


    \begin{document}

    \maketitle

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \begin{abstract}
    Bu çalışmada, Online News Popularity veri kümesi üzerinde üç farklı özellik seçimi yönteminin ikili sınıflandırma performansına etkisi incelenmiştir. Filtreleme (Pearson Korelasyonu), Sarmalayıcı (RFE + Lojistik Regresyon) ve Gömülü (Random Forest) yöntemleri kullanılarak en önemli 15 özellik belirlenmiştir. Lojistik Regresyon sınıflandırıcısı ile 5-fold cross validation yöntemi uygulanarak modeller değerlendirilmiştir. Deneysel sonuçlar, Sarmalayıcı (RFE) yönteminin 15 özellik ile \%65.10 doğruluk oranına ulaşarak özellik seçimi yöntemleri arasında en başarılı sonucu verdiğini göstermektedir. Ayrıca optimal özellik sayısı analizi yapılarak, RFE ile 22 özellik kullanıldığında \%65.63 doğruluk oranına ulaşılmış olup, bu değer tüm özelliklerin (\%65.52) kullanıldığı durumun üzerindedir. Bu bulgular, özellik seçiminin model performansını artırırken hesaplama maliyetini de önemli ölçüde azalttığını ortaya koymaktadır.
    \end{abstract}

    \begin{IEEEkeywords}
    Özellik seçimi, Lojistik regresyon, Pearson korelasyonu, RFE, Random Forest, Online News Popularity, Makine öğrenmesi
    \end{IEEEkeywords}


    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \section{Giriş}

    Günümüzde çevrimiçi haber platformları, milyonlarca makalenin paylaşıldığı ve tüketildiği dijital ortamlardır. Bir haberin popüler olup olmayacağını tahmin edebilmek, içerik üreticileri ve medya kuruluşları için stratejik bir öneme sahiptir. Bu bağlamda makine öğrenmesi yöntemleri, çeşitli özellikler kullanarak haber popülerliğini tahmin etmekte yaygın olarak kullanılmaktadır~\cite{fernandes2015proactive}.

    Özellik seçimi, makine öğrenmesi modellerinin performansını artırmak, eğitim süresini kısaltmak ve aşırı öğrenmeyi (overfitting) önlemek için kritik bir ön işleme adımıdır~\cite{guyon2003introduction}. Yüksek boyutlu veri kümelerinde, gereksiz veya gürültülü özellikler modelin genelleme yeteneğini olumsuz etkileyebilmektedir. Bu nedenle, en ayırt edici özelliklerin seçilmesi model performansı açısından büyük önem taşımaktadır.

    Bu çalışmanın amacı, UCI Machine Learning Repository'den alınan Online News Popularity veri kümesi üzerinde farklı özellik seçimi yöntemlerinin sınıflandırma performansına etkisini karşılaştırmalı olarak analiz etmektir. Çalışma kapsamında Filtreleme (Pearson Korelasyonu), Sarmalayıcı (RFE + Lojistik Regresyon) ve Gömülü (Random Forest Feature Importance) yöntemleri uygulanarak en önemli 15 özellik belirlenmiş ve bu özelliklerle eğitilen modellerin performansları karşılaştırılmıştır.


    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \section{Yöntem ve Veri Kümesi}

    \subsection{Veri Kümesi}

    Bu çalışmada Mashable platformundan derlenen Online News Popularity veri kümesi kullanılmıştır~\cite{fernandes2015proactive}. Veri kümesi, 39.644 haber makalesine ait 61 özellik içermektedir. Her bir makale için içerik özellikleri (kelime sayısı, görsel sayısı vb.), zaman özellikleri (yayın günü, hafta sonu durumu), anahtar kelime metrikleri, doğal dil işleme özellikleri (LDA konu modeli, sentiment analizi) ve referans bilgileri (bağlantı sayısı, paylaşım istatistikleri) bulunmaktadır.

    \subsection{Veri Ön İşleme}

    Veri ön işleme adımları aşağıdaki şekilde gerçekleştirilmiştir:

    \begin{enumerate}
        \item \textbf{Gereksiz özellik çıkarımı:} Ayırt edici bilgi içermeyen \texttt{url} ve \texttt{timedelta} özellikleri veri kümesinden çıkarılmıştır.
        
        \item \textbf{Hedef değişken dönüşümü:} \texttt{shares} sütunu medyan değeri olan 1.400 eşik alınarak ikili sınıf etiketine dönüştürülmüştür. $shares \geq 1400$ durumunda $y=1$ (popüler), aksi halde $y=0$ (popüler değil) olarak etiketlenmiştir.
        
        \item \textbf{Veri bölme:} İşlenmiş veri kümesi \%80 eğitim ve \%20 test olarak ayrılmıştır.
        
        \item \textbf{Cross validation:} Eğitim verisi üzerinde 5-fold stratified cross validation yöntemi uygulanmıştır.
    \end{enumerate}

    İşleme sonrasında toplam 59 özellik elde edilmiştir.

    \subsection{Özellik Seçimi Yöntemleri}

    \subsubsection{Filtreleme Yöntemi (Pearson Korelasyonu)}

    Filtreleme yönteminde, her bir özellik ile hedef değişken arasındaki Pearson korelasyon katsayısı hesaplanmıştır~\cite{hall1999correlation}. Pearson korelasyon katsayısı, iki değişken arasındaki doğrusal ilişkinin gücünü ve yönünü ölçer. Bu yöntemde mutlak değeri en yüksek korelasyona sahip 15 özellik seçilmiştir. Filtreleme yöntemi model bağımsız olması ve hesaplama açısından verimli olması ile avantaj sağlamaktadır.

    \subsubsection{Sarmalayıcı Yöntem (RFE + Lojistik Regresyon)}

    Sarmalayıcı yöntemde Recursive Feature Elimination (RFE) algoritması Lojistik Regresyon sınıflandırıcısı ile birlikte kullanılmıştır~\cite{guyon2002gene}. RFE, başlangıçta tüm özelliklerle model eğitir ve her iterasyonda model katsayılarına göre en az önemli özelliği elemine eder. Bu süreç istenilen özellik sayısına (15) ulaşılana kadar devam eder. Model parametreleri olarak \texttt{solver='lbfgs'} ve \texttt{max\_iter=1000} kullanılmıştır.

    \subsubsection{Gömülü Yöntem (Random Forest Feature Importance)}

    Gömülü yöntemde Random Forest sınıflandırıcısının özellik önem skorları kullanılmıştır~\cite{breiman2001random}. Random Forest, birden fazla karar ağacı eğiterek her özelliğin ağaçlardaki bölünmelere katkısını hesaplar. Gini safsızlığı (impurity) azalmasına göre önem skorları belirlenir. En yüksek önem skoruna sahip 15 özellik seçilmiştir. Model 100 ağaç (\texttt{n\_estimators=100}) ile eğitilmiştir.

    \subsection{Sınıflandırıcı Model}

    Performans karşılaştırması için Lojistik Regresyon sınıflandırıcısı kullanılmıştır. Model parametreleri varsayılan değerlerde tutulmuş (\texttt{C=1.0}, \texttt{solver='lbfgs'}) ve 5-fold stratified cross validation ile eğitilmiştir. Aşırı öğrenme tespiti için eğitim ve validasyon skorları karşılaştırılmıştır.

    \subsection{Performans Metrikleri}

    Model performansı aşağıdaki metriklerle değerlendirilmiştir:
    \begin{itemize}
        \item \textbf{Doğruluk (Accuracy):} Doğru tahmin edilen örneklerin toplam örnek sayısına oranı.
        \item \textbf{F1-Skoru:} Kesinlik ve duyarlılığın harmonik ortalaması.
        \item \textbf{Eğitim Süresi:} Modelin eğitim için harcadığı süre (saniye).
    \end{itemize}


    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \section{Deneysel Analiz}

    \subsection{Özellik Seçimi Sonuçları}

    Her bir özellik seçimi yönteminin belirlediği en önemli 15 özellik Tablo~\ref{tab:selected_features}'de verilmiştir. Her yöntem farklı özellik kümeleri seçmiş olup, yalnızca \texttt{kw\_avg\_avg} özelliği üç yöntemde de ortak olarak seçilmiştir.

    \begin{table}[H]
    \caption{Farklı Yöntemlerle Seçilen Özellikler}
    \label{tab:selected_features}
    \centering
    \footnotesize
    \begin{tabular}{|c|l|l|l|}
    \hline
    \textbf{Sıra} & \textbf{Filtreleme} & \textbf{Sarmalayıcı} & \textbf{Gömülü} \\
    \hline
    1 & LDA\_02 & n\_non\_stop\_words & kw\_avg\_avg \\
    2 & kw\_avg\_avg & n\_non\_stop\_uniq. & kw\_max\_avg \\
    3 & data\_ch\_is\_world & n\_unique\_tokens & LDA\_02 \\
    4 & is\_weekend & kw\_avg\_avg & self\_ref\_min\_sh. \\
    5 & data\_ch\_is\_enter. & kw\_max\_avg & kw\_avg\_min \\
    6 & data\_ch\_is\_socmed & data\_ch\_is\_tech & kw\_avg\_max \\
    7 & weekday\_is\_sat. & is\_weekend & LDA\_01 \\
    8 & data\_ch\_is\_tech & LDA\_00 & self\_ref\_avg\_sh. \\
    9 & LDA\_04 & data\_ch\_is\_socmed & LDA\_04 \\
    10 & kw\_min\_avg & kw\_min\_min & LDA\_00 \\
    11 & num\_hrefs & kw\_avg\_max & n\_unique\_tokens \\
    12 & weekday\_is\_sunday & kw\_min\_avg & global\_subject. \\
    13 & LDA\_01 & kw\_avg\_min & n\_non\_stop\_uniq. \\
    14 & global\_sent\_polar. & self\_ref\_avg\_sh. & avg\_token\_length \\
    15 & num\_keywords & kw\_max\_min & LDA\_03 \\
    \hline
    \end{tabular}
    \end{table}

    \subsection{Ortak Özellik Analizi}

    Yöntemler arasındaki özellik kesişimi analiz edildiğinde, Filtreleme ve Sarmalayıcı arasında 5, Filtreleme ve Gömülü arasında 4, Sarmalayıcı ve Gömülü arasında 8 ortak özellik bulunmaktadır. Tablo~\ref{tab:common_features}'da ortak bulunan özellikler gösterilmiştir.

     \begin{table}[H]
    \caption{Yöntemler Arasında Ortak Özellikler (En Az 2 Yöntemde Seçilenler)}
    \label{tab:common_features}
    \centering
    \footnotesize
    \begin{tabular}{|l|c|c|c|}
    \hline
    \textbf{Özellik} & \textbf{Filt.} & \textbf{Sarm.} & \textbf{Göm.} \\
    \hline
    \multicolumn{4}{|c|}{\textit{Üç Yöntemde Ortak (1 özellik)}} \\
    \hline
    kw\_avg\_avg & \checkmark & \checkmark & \checkmark \\
    \hline
    \multicolumn{4}{|c|}{\textit{Filtreleme + Gömülü (3 özellik)}} \\
    \hline
    LDA\_02 & \checkmark & & \checkmark \\
    LDA\_04 & \checkmark & & \checkmark \\
    LDA\_01 & \checkmark & & \checkmark \\
    \hline
    \multicolumn{4}{|c|}{\textit{Filtreleme + Sarmalayıcı (4 özellik)}} \\
    \hline
    is\_weekend & \checkmark & \checkmark & \\
    data\_channel\_is\_tech & \checkmark & \checkmark & \\
    data\_channel\_is\_socmed & \checkmark & \checkmark & \\
    kw\_min\_avg & \checkmark & \checkmark & \\
    \hline
    \multicolumn{4}{|c|}{\textit{Sarmalayıcı + Gömülü (7 özellik)}} \\
    \hline
    LDA\_00 & & \checkmark & \checkmark \\
    kw\_max\_avg & & \checkmark & \checkmark \\
    n\_unique\_tokens & & \checkmark & \checkmark \\
    n\_non\_stop\_unique\_tokens & & \checkmark & \checkmark \\
    kw\_avg\_max & & \checkmark & \checkmark \\
    kw\_avg\_min & & \checkmark & \checkmark \\
    self\_reference\_avg\_sharess & & \checkmark & \checkmark \\
    \hline
    \end{tabular}
    \end{table}

    \subsection{Model Performans Karşılaştırması}

    Tüm özellikler ve özellik seçimi yöntemleriyle elde edilen alt kümeler üzerinde Lojistik Regresyon modeli eğitilmiş ve test sonuçları Tablo~\ref{tab:performance}'de özetlenmiştir.

    \begin{table}[H]
    \caption{Lojistik Regresyon Performans Sonuçları}
    \label{tab:performance}
    \centering
    \begin{tabular}{|l|c|c|c|c|}
    \hline
    \textbf{Yöntem} & \textbf{Öz. Sayısı} & \textbf{Accuracy} & \textbf{F1-Skor} & \textbf{Süre (s)} \\
    \hline
    Tüm Özellikler & 58 & 0.6552 & 0.6544 & 0.429 \\
    Filtreleme & 15 & 0.6431 & 0.6413 & \textbf{0.048} \\
    \textbf{Sarmalayıcı (RFE)} & 15 & 0.6510 & 0.6502 & 0.099 \\
    Gömülü & 15 & 0.6278 & 0.6253 & 0.055 \\
    \textbf{RFE Optimal} & 22 & \textbf{0.6563} & \textbf{0.6553} & 0.000 \\
    \hline
    \end{tabular}
    \end{table}

    Sonuçlara göre:
    \begin{itemize}
        \item \textbf{RFE Optimal (22 özellik)} yöntemi \%65.63 doğruluk oranı ile tüm yöntemler arasında en yüksek performansı sağlamıştır.
        \item Tüm özelliklerle (58 özellik) eğitilen model \%65.52 doğruluk oranına ulaşmıştır.
        \item Özellik seçimi yöntemleri arasında \textbf{Sarmalayıcı (RFE)} yöntemi 15 özellik ile \%65.10 doğruluk oranı ile en başarılı sonucu vermiştir.
        \item Filtreleme yöntemi \%64.31, Gömülü yöntem ise \%62.78 doğruluk oranlarına ulaşmıştır.
        \item Eğitim süresi açısından özellik seçimi yöntemleri önemli avantaj sağlamıştır. Filtreleme yöntemi 0.048 saniye ile en hızlı eğitim süresine sahiptir.
    \end{itemize}

    \subsection{Optimal Özellik Sayısı Analizi}

    RFE yönteminin en başarılı özellik seçimi yöntemi olduğu tespit edildikten sonra, optimal özellik sayısını belirlemek amacıyla ek bir analiz gerçekleştirilmiştir. Bu analizde, RFE ile 1'den başlayarak başarı düşene kadar farklı özellik sayıları test edilmiş ve her bir durumda model performansı ölçülmüştür. Şekil~\ref{fig:optimal_feature}'de optimal özellik sayısı analizi gösterilmektedir.

    \begin{figure}[H]
        \centering
        \includegraphics[width=\linewidth]{optimal_feature_count_analysis.png}
        \caption{Optimal Özellik Sayısı Analizi: RFE ile farklı özellik sayılarının doğruluk performansına etkisi. Yeşil çizgi optimal noktayı (22 özellik, \%65.63 doğruluk) göstermektedir.}
        \label{fig:optimal_feature}
    \end{figure}

    Optimal özellik sayısı analizi incelendiğinde:
    \begin{itemize}
        \item \textbf{Optimal nokta:} 22 özellik ile \%65.63 doğruluk oranına ulaşılmıştır. Bu değer, 58 özellik kullanıldığında elde edilen \%65.52 değerinin üzerindedir.
        \item \textbf{Performans eğrisi:} Özellik sayısı arttıkça performans genel olarak artmakta, ancak belirli bir noktadan sonra (yaklaşık 20-25 özellik) plato yapmaktadır.
        \item \textbf{Boyut azaltma:} 22 özellik ile 58 özelliğe kıyasla \%62 boyut azaltımı sağlanırken, performansta kayıp yaşanmamış, aksine küçük bir artış gözlemlenmiştir.
        \item \textbf{Aşırı öğrenme riski:} Çok fazla özellik kullanımı aşırı öğrenme riskini artırabilir. Optimal özellik sayısı bu riski minimize etmektedir.
    \end{itemize}

    \subsection{Aşırı Öğrenme Analizi}

    Tüm yöntemler için eğitim ve validasyon skorları arasındaki fark hesaplanmıştır:
    \begin{itemize}
        \item Tüm Özellikler: Fark = 0.0023 (Aşırı öğrenme tespit edilmedi)
        \item Filtreleme: Fark = 0 (Aşırı öğrenme tespit edilmedi)
        \item Sarmalayıcı: Fark = 0.0006 (Aşırı öğrenme tespit edilmedi)
        \item Gömülü: Fark = 0.0014 (Aşırı öğrenme tespit edilmedi)
    \end{itemize}

    Hiçbir yöntemde aşırı öğrenme tespit edilmemiştir. Bu durum, Lojistik Regresyonun L2 regularization özelliği sayesinde modelin genelleme yeteneğini koruduğunu göstermektedir.

    \subsection{Karışıklık Matrisleri}

    En başarılı özellik seçimi yöntemi olan Sarmalayıcı (RFE) için karışıklık matrisi Şekil~\ref{fig:confusion_matrix}'de verilmiştir.

    \begin{figure}[H]
        \centering
        \includegraphics[width=\linewidth]{best_method_confusion_matrix.png}
        \caption{Sarmalayıcı (RFE) Yöntemi İçin Karışıklık Matrisi (15 özellik)}
        \label{fig:confusion_matrix}
    \end{figure}

    Karışıklık matrisine göre:
    \begin{itemize}
        \item \textbf{True Negative (TN):} 2217 örnek doğru olarak ``popüler değil'' sınıfına atanmıştır.
        \item \textbf{False Positive (FP):} 1481 örnek yanlışlıkla ``popüler'' olarak tahmin edilmiştir.
        \item \textbf{False Negative (FN):} 1286 örnek yanlışlıkla ``popüler değil'' olarak tahmin edilmiştir.
        \item \textbf{True Positive (TP):} 2945 örnek doğru olarak ``popüler'' sınıfına atanmıştır.
    \end{itemize}

    Optimal RFE yöntemi (22 özellik) için karışıklık matrisi Şekil~\ref{fig:optimal_confusion}'da gösterilmektedir.

    \begin{figure}[H]
        \centering
        \includegraphics[width=\linewidth]{optimal_rfe_confusion_matrix.png}
        \caption{RFE Optimal Yöntemi İçin Karışıklık Matrisi (22 özellik)}
        \label{fig:optimal_confusion}
    \end{figure}

    Optimal RFE yöntemi, 22 özellik kullanarak tüm özelliklerden daha iyi performans göstermektedir. Bu durum, gereksiz özelliklerin modele gürültü kattığını ve optimal özellik alt kümesinin daha iyi genelleme yeteneği sağladığını göstermektedir.

    \subsection{Özellik Seçimi Yöntemleri Karşılaştırması}

    Üç temel özellik seçimi yönteminin (Filtreleme, Sarmalayıcı, Gömülü) karışıklık matrisleri Şekil~\ref{fig:all_confusion}'da karşılaştırmalı olarak gösterilmiştir.

    \begin{figure}[H]
        \centering
        \includegraphics[width=\linewidth]{feature_selection_confusion_matrices.png}
        \caption{Özellik Seçimi Yöntemleri İçin Karışıklık Matrisleri Karşılaştırması}
        \label{fig:all_confusion}
    \end{figure}

    Karışıklık matrisleri incelendiğinde yöntemler arasında belirgin farklılıklar gözlemlenmektedir:

    \begin{itemize}
        \item \textbf{Filtreleme (Pearson):} Popüler haberleri tespit etmede (TP) makul performans gösterirken, True Negative (TN) değeri nispeten düşüktür. Bu durum, yöntemin doğrusal korelasyona dayalı olmasından kaynaklanmakta ve karmaşık ilişkileri yakalayamamaktadır.
        
        \item \textbf{Sarmalayıcı (RFE):} En dengeli dağılıma sahiptir. TP ve TN değerleri dengeli olup, özellik seçimi yöntemleri arasında en başarılı performansı sergilemektedir. RFE'nin Lojistik Regresyon ile optimize edilmiş olması bu başarıyı açıklamaktadır.
        
        \item \textbf{Gömülü (Random Forest):} En düşük TP değerine sahiptir, bu da popüler haberleri tespit etmede zorluk yaşadığını gösterir. Random Forest'ın özellik önem skorları, Lojistik Regresyon sınıflandırıcısı için optimal olmayan bir özellik kümesi seçmiş olabilir.
    \end{itemize}

    \subsection{Yöntem Performans Karşılaştırma Grafikleri}

    Yöntemlerin performans karşılaştırması Şekil~\ref{fig:method_comparison}'de grafik olarak sunulmuştur.

    \begin{figure}[H]
        \centering
        \includegraphics[width=\linewidth]{method_comparison.png}
        \caption{Temel Yöntemler Performans Karşılaştırması: Doğruluk, F1-Skor ve Eğitim Süresi metrikleri açısından yöntemlerin karşılaştırılması}
        \label{fig:method_comparison}
    \end{figure}

    Performans karşılaştırma grafiği analiz edildiğinde aşağıdaki çıkarımlar yapılabilir:

    \begin{itemize}
        \item \textbf{Doğruluk-Verimlilik Dengesi:} Tüm özellikler en yüksek doğruluğu sağlarken, eğitim süresi de en uzundur (0.429s). Özellik seçimi yöntemleri bu süreyi yaklaşık 4-9 kat kısaltmaktadır.
        
        \item \textbf{Yöntemler Arası Performans Farkı:} Tüm özellikler (\%65.52) ile Sarmalayıcı (\%65.10) arasındaki fark sadece \%0.42'dir. Bu, 15 özellik ile 58 özelliğe çok yakın performans elde edilebileceğini göstermektedir.
        
        \item \textbf{F1-Skor Tutarlılığı:} Accuracy ve F1-skor değerleri tüm yöntemlerde birbirine yakındır, bu da sınıf dengesizliğinin ciddi bir problem olmadığını göstermektedir.
        
        \item \textbf{En Hızlı Yöntem:} Filtreleme yöntemi 0.048s ile en kısa eğitim süresine sahiptir, ancak doğruluk açısından Sarmalayıcı'nın gerisinde kalmaktadır.
        
        \item \textbf{Gömülü Yöntem Performansı:} Random Forest tabanlı özellik seçimi, Lojistik Regresyon sınıflandırıcısı ile en düşük performansı vermiştir. Bu durum, ağaç tabanlı önem skorlarının doğrusal modeller için optimize olmadığını göstermektedir.
    \end{itemize}

    Optimal RFE dahil tüm yöntemlerin karşılaştırması Şekil~\ref{fig:method_comparison_optimal}'de gösterilmektedir.

    \begin{figure}[H]
        \centering
        \includegraphics[width=\linewidth]{method_comparison_with_optimal.png}
        \caption{Optimal RFE Dahil Yöntem Karşılaştırması}
        \label{fig:method_comparison_optimal}
    \end{figure}

    Optimal RFE dahil karşılaştırma grafiğinden çıkarılabilecek sonuçlar:

    \begin{itemize}
        \item \textbf{RFE Optimal üstünlüğü:} 22 özellik ile \%65.63 doğruluk oranı, hem tüm özellikleri (\%65.52) hem de 15 özellikli RFE'yi (\%65.10) geride bırakmaktadır.
        
        \item \textbf{Özellik sayısı optimizasyonu:} Bu sonuç, özellik sayısının 15 ile sınırlandırılmasının optimal olmadığını, daha fazla özelliğin performansı artırabileceğini göstermektedir.
        
        \item \textbf{Hesaplama maliyeti:} Optimal özellik sayısı belirleme işlemi ek hesaplama maliyeti gerektirse de, elde edilen performans kazancı bu maliyeti dengelemektedir.
    \end{itemize}


    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \section{Sonuç}

    Bu çalışmada, Online News Popularity veri kümesi üzerinde üç farklı özellik seçimi yönteminin sınıflandırma performansına etkisi incelenmiştir. Deneysel sonuçlar önemli bulgular ortaya koymuştur:

    \begin{itemize}
        \item \textbf{Optimal özellik sayısı analizi:} RFE yöntemi ile yapılan kapsamlı analiz sonucunda, 22 özellik ile \%65.63 doğruluk oranına ulaşılmış olup, bu değer 58 özellik kullanıldığında elde edilen \%65.52 değerinin üzerindedir. Bu sonuç, gereksiz özelliklerin modele gürültü kattığını ve optimal özellik alt kümesinin daha iyi genelleme yeteneği sağladığını göstermektedir.
        
        \item \textbf{Özellik seçimi yöntemleri karşılaştırması:} Sarmalayıcı (RFE) yöntemi, 15 özellik ile \%65.10 doğruluk oranı sağlayarak özellik seçimi yöntemleri arasında en başarılı performansı sergilemiştir. Bu sonuç, RFE yönteminin Lojistik Regresyon için optimize edilmiş özellik seçimi yapmasından kaynaklanmaktadır.
        
        \item \textbf{Özellik önemi:} Anahtar kelime metrikleri (\texttt{kw\_avg\_avg}) tüm yöntemlerde en önemli özellik olarak belirlenmiş olup, haberlerin popülerliğinde anahtar kelimelerin kritik rol oynadığını ortaya koymaktadır.
        
        \item \textbf{Hesaplama verimliliği:} Özellik seçimi, eğitim süresini yaklaşık 4-9 kat kısaltarak hesaplama verimliliği sağlamıştır.
    \end{itemize}

    Sonuç olarak, bu çalışma optimal özellik sayısının belirlenmesinin model performansını artırabileceğini ve özellik seçiminin sadece boyut azaltma değil, aynı zamanda performans iyileştirme aracı olarak da kullanılabileceğini göstermektedir. Gelecek çalışmalarda, farklı sınıflandırıcı algoritmalarının (Random Forest, SVM, Gradient Boosting vb.) özellik seçimi yöntemleriyle birlikte değerlendirilmesi planlanmaktadır.


    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \begin{thebibliography}{99}

    \bibitem{fernandes2015proactive}
    K. Fernandes, P. Vinagre, and P. Cortez, ``A proactive intelligent decision support system for predicting the popularity of online news,'' in \textit{Portuguese Conference on Artificial Intelligence}, Springer, 2015, pp. 535--546.

    \bibitem{guyon2003introduction}
    I. Guyon and A. Elisseeff, ``An introduction to variable and feature selection,'' \textit{Journal of machine learning research}, vol. 3, pp. 1157--1182, 2003.

    \bibitem{hall1999correlation}
    M. A. Hall, ``Correlation-based feature selection for machine learning,'' Ph.D. dissertation, University of Waikato, 1999.

    \bibitem{guyon2002gene}
    I. Guyon, J. Weston, S. Barnhill, and V. Vapnik, ``Gene selection for cancer classification using support vector machines,'' \textit{Machine learning}, vol. 46, no. 1-3, pp. 389--422, 2002.

    \bibitem{breiman2001random}
    L. Breiman, ``Random forests,'' \textit{Machine learning}, vol. 45, no. 1, pp. 5--32, 2001.

    \end{thebibliography}

    \end{document}
