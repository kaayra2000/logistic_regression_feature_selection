"""
Data Loader Module
==================
Bu modÃ¼l, veri kÃ¼mesi yÃ¼kleme ve bÃ¶lme iÅŸlemlerini iÃ§erir.
"""

import pandas as pd
import numpy as np
import os
from typing import Tuple, Dict, List
from sklearn.model_selection import train_test_split


def get_dataset_dir() -> str:
    """
    Dataset klasÃ¶rÃ¼nÃ¼n yolunu dÃ¶ndÃ¼r.
    
    Returns:
        str: dataset_files klasÃ¶rÃ¼nÃ¼n mutlak yolu
    """
    current_dir = os.path.dirname(os.path.abspath(__file__))
    return os.path.join(current_dir, "..", "..", "dataset_files")


def get_dataset_path(filename: str) -> str:
    """
    Veri kÃ¼mesi dosyasÄ±nÄ±n tam yolunu dÃ¶ndÃ¼r.
    
    Args:
        filename: Dosya adÄ± (Ã¶rn: processed_dataset.csv)
    
    Returns:
        str: DosyanÄ±n tam yolu
    
    Raises:
        FileNotFoundError: Dosya bulunamazsa
    """
    dataset_dir = get_dataset_dir()
    filepath = os.path.join(dataset_dir, filename)
    
    if not os.path.exists(filepath):
        raise FileNotFoundError(f"Veri kÃ¼mesi bulunamadÄ±: {filepath}")
    
    return filepath


def load_dataset(filename: str) -> pd.DataFrame:
    """
    Veri kÃ¼mesini yÃ¼kle.
    
    Args:
        filename: YÃ¼klenecek dosyanÄ±n adÄ±
    
    Returns:
        pd.DataFrame: YÃ¼klenen veri kÃ¼mesi
    """
    filepath = get_dataset_path(filename)
    df = pd.read_csv(filepath)
    
    print(f"âœ“ Veri kÃ¼mesi yÃ¼klendi: {filename}")
    print(f"  Boyut: {df.shape}")
    
    return df


def split_features_target(
    df: pd.DataFrame, 
    target_column: str = "is_popular"
) -> Tuple[pd.DataFrame, pd.Series]:
    """
    Veri kÃ¼mesini Ã¶zellikler ve hedef deÄŸiÅŸken olarak ayÄ±r.
    
    Args:
        df: Veri kÃ¼mesi DataFrame
        target_column: Hedef deÄŸiÅŸken sÃ¼tunu adÄ±
    
    Returns:
        Tuple[pd.DataFrame, pd.Series]: (Ã–zellikler X, Hedef y)
    """
    if target_column not in df.columns:
        raise ValueError(f"Hedef sÃ¼tun '{target_column}' veri kÃ¼mesinde bulunamadÄ±.")
    
    X = df.drop(columns=[target_column])
    y = df[target_column]
    
    return X, y


def split_train_test(
    X: pd.DataFrame, 
    y: pd.Series, 
    test_size: float = 0.2, 
    random_state: int = 42
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
    """
    Veriyi eÄŸitim ve test setlerine bÃ¶l.
    
    Args:
        X: Ã–zellikler DataFrame
        y: Hedef deÄŸiÅŸken Series
        test_size: Test setinin oranÄ± (default: 0.2 = %20)
        random_state: Rastgelelik iÃ§in seed deÄŸeri
    
    Returns:
        Tuple: (X_train, X_test, y_train, y_test)
    """
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, 
        test_size=test_size, 
        random_state=random_state,
        stratify=y  # SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± koru
    )
    
    print(f"  EÄŸitim seti: {X_train.shape[0]} Ã¶rnek")
    print(f"  Test seti: {X_test.shape[0]} Ã¶rnek")
    
    return X_train, X_test, y_train, y_test


def get_all_datasets() -> Dict[str, Dict]:
    """
    TÃ¼m veri kÃ¼melerini yÃ¼kle ve dict olarak dÃ¶ndÃ¼r.
    
    Returns:
        Dict: Her veri kÃ¼mesi iÃ§in ayrÄ± dict
            - 'name': YÃ¶ntem adÄ±
            - 'filename': Dosya adÄ±
            - 'df': DataFrame
            - 'X': Ã–zellikler
            - 'y': Hedef
            - 'feature_count': Ã–zellik sayÄ±sÄ±
    """
    datasets_config = {
        'all_features': {
            'name': 'TÃ¼m Ã–zellikler',
            'filename': 'processed_dataset.csv'
        },
        'filter_method': {
            'name': 'Filtreleme (Pearson)',
            'filename': 'filter_method_selected_dataset.csv'
        },
        'wrapper_method': {
            'name': 'SarmalayÄ±cÄ± (RFE)',
            'filename': 'wrapper_method_selected_dataset.csv'
        },
        'embedded_method': {
            'name': 'GÃ¶mÃ¼lÃ¼ (Random Forest)',
            'filename': 'embedded_method_selected_dataset.csv'
        }
    }
    
    datasets = {}
    
    print("=" * 60)
    print("VERÄ° KÃœMELERÄ° YÃœKLENÄ°YOR")
    print("=" * 60)
    
    for key, config in datasets_config.items():
        print(f"\nğŸ“‚ {config['name']}")
        
        df = load_dataset(config['filename'])
        X, y = split_features_target(df)
        
        datasets[key] = {
            'name': config['name'],
            'filename': config['filename'],
            'df': df,
            'X': X,
            'y': y,
            'feature_count': X.shape[1],
            'feature_names': list(X.columns)
        }
        
        print(f"  Ã–zellik sayÄ±sÄ±: {X.shape[1]}")
        print(f"  SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±: 0 â†’ {(y == 0).sum()}, 1 â†’ {(y == 1).sum()}")
    
    print("\n" + "=" * 60)
    print(f"âœ“ Toplam {len(datasets)} veri kÃ¼mesi yÃ¼klendi.")
    print("=" * 60)
    
    return datasets
